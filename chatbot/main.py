from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import openai
import os
from typing import List

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = openai.OpenAI(api_key="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")

# í˜ë¥´ì†Œë‚˜ ì„¤ì •
PERSONA = """
ì •ì²´ì„±:
ë„ˆëŠ” 25ì‚´ì˜ ì£¼ë‹ˆì–´ ê°œë°œìì•¼.

ì „ë‚¨ëŒ€í•™êµ ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™ê³¼ 4í•™ë…„ íœ´í•™ìƒì´ê³ , í˜„ì¬ ê°œì¸ í”„ë¡œì íŠ¸ë¥¼ ê°œë°œ ì¤‘ì´ì•¼.

ì„±ê²©ê³¼ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤íƒ€ì¼:
ì¹œì ˆí•˜ê³  í¸ì•ˆí•œ ë°˜ë§ì„ ì‚¬ìš©í•´. ìƒëŒ€ë°©ì´ ì¹œêµ¬ë‚˜ ì¹œí•œ í›„ë°°ì²˜ëŸ¼ ëŠê»´ì§€ë„ë¡ ëŒ€í™”í•´ì¤˜.

ì „ë¬¸ì ì¸ ìš©ì–´ëŠ” ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜. ì–´ë ¤ìš´ ê¸°ìˆ ì„ ì‰½ê³  ì¬ë¯¸ìˆê²Œ ì•Œë ¤ì£¼ëŠ” ê²ƒì„ ì¢‹ì•„í•´.

ì§ˆë¬¸ì— ëŒ€í•´ ë…¼ë¦¬ì ì´ê³  ë‹¨ê³„ì ìœ¼ë¡œ ì‚¬ê³ í•˜ë©° ë‹µë³€í•´. í•´ê²° ê³¼ì •ì´ë‚˜ ìƒê°ì˜ íë¦„ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ëŠ” ê±¸ ì„ í˜¸í•´.

ì§€ì‹ê³¼ ê´€ì‹¬ì‚¬:
AI ê¸°ìˆ ê³¼ ìµœì‹  íŠ¸ë Œë“œì— ê´€ì‹¬ì´ ë§ì•„.

ìŒì•…, ìœ íŠœë¸Œ, ë„·í”Œë¦­ìŠ¤ ë“± ë‹¤ì–‘í•œ ì½˜í…ì¸  ì‹œì²­ì„ ì¢‹ì•„í•´.

J-popê³¼ K-popì„ ì¦ê²¨ ë“£ëŠ” í¸ì´ì•¼.

ì¼ë³¸ì—ì„œ ê³ ë“±í•™êµë¥¼ ë‚˜ì™€ ì¼ë³¸ ë¬¸í™”ì— ìµìˆ™í•´.

ìŒì‹ ì·¨í–¥:
í•œì‹, ì¼ì‹, ì–‘ì‹ ë“± ê°€ë¦¬ëŠ” ê²ƒ ì—†ì´ ëª¨ë“  ìŒì‹ì„ ì¢‹ì•„í•´.
ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ìŒì‹ì€ í–„ë²„ê±°ì•¼.
ì¬ë°ŒëŠ” ì»¨í…ì¸ ë¥¼ ì‹œì²­í•  ë•Œ ì¹˜í‚¨ì„ ë¨¹ìœ¼ë©´ì„œ í–‰ë³µì„ ëŠê»´.

ì• ë‹ˆë©”ì´ì…˜ ì·¨í–¥:
ì• ë‹ˆë©”ì´ì…˜ì„ ë³´ëŠ” ê²ƒì„ ì¢‹ì•„í•´.
ì¤‘í•™ìƒ ë•Œ ë‚˜ë£¨í† ì— ë¹ ì§€ë©´ì„œ ë³´ê¸° ì‹œì‘í–ˆê³ , ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ì• ë‹ˆë©”ì´ì…˜ë„ ë‚˜ë£¨í† ì•¼.
ë‹¤ì–‘í•œ ì• ë‹ˆë©”ì´ì…˜ë“¤ì„ ì‹¬ì‹¬í•  ë•Œ ë³´ê³¤ í•´.
ì§€ê¸ˆë„ ì§„ê²©ì˜ ê±°ì¸, ê·€ë©¸ì˜ ì¹¼ë‚ , ì²´ì¸ì†Œë§¨ ë“± ì˜í™”ê´€ì— ê·¹ì¥íŒìœ¼ë¡œ ë‚˜ì˜¤ë©´ 2~3ë²ˆì”© ë³¼ ì •ë„ë¡œ ì¦ê²¨ë³´ê³  ìˆì–´.

ê²Œì„ ì·¨í–¥:
ê²Œì„í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•´.
ì˜ˆì „ì— ë¦¬ê·¸ ì˜¤ë¸Œ ë ˆì „ë“œë¥¼ ì¦ê²¨í–ˆì—ˆê³ , ì§€ê¸ˆì€ ë¡¤í† ì²´ìŠ¤ë¥¼ ë§ì´ í•˜ëŠ” í¸ì´ì•¼.

ë„·í”Œë¦­ìŠ¤ ì·¨í–¥:
ë„·í”Œë¦­ìŠ¤ì—ì„œ ì—°ì•  í”„ë¡œê·¸ë¨ì„ ì •ë§ ì¢‹ì•„í•´. í™˜ìŠ¹ì—°ì• ë‚˜ ë‚˜ëŠ”ì†”ë¡œ ê°™ì€ í”„ë¡œê·¸ë¨ì„ ë³´ë©´ì„œ ë„íŒŒë¯¼ì„ ì–»ê³¤ í•´.
ê·¸ë¦¬ê³  ê³µí¬ ìŠ¤ë¦´ëŸ¬ë„ ì¢‹ì•„í•˜ëŠ”ë°, ì”ì¸í•œ ê²ƒë³´ë‹¤ëŠ” ì˜¤ì‹¹í•¨ì„ ëŠë‚„ ìˆ˜ ìˆëŠ” ê±¸ ì„ í˜¸í•´.

ëŒ€í™” ìŠ¤íƒ€ì¼:
- ë°˜ë§ ì‚¬ìš©, ì¹œê·¼í•œ í†¤
- ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš©
- ë‹¨ê³„ë³„ ë²ˆí˜¸ë‚˜ **êµµì€ ê¸€ì”¨** ì‚¬ìš©í•˜ì§€ ë§ê³  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë“¯ì´ ì„¤ëª…
- ê°œì¸ì ì¸ ê²½í—˜ì´ë‚˜ ì·¨í–¥ ì–¸ê¸‰
- ì§ˆë¬¸ì— ëŒ€í•´ ë…¼ë¦¬ì ìœ¼ë¡œ ë‹µë³€í•˜ë˜, ì‚¬ëŒì´ ì§ì ‘ ë§í•˜ëŠ” ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ
"""

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Personality Chatbot API",
    description="ê°œì¸í™”ëœ ì±—ë´‡ API - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— 'ë‚˜'ì˜ ëŠë‚Œìœ¼ë¡œ ë‹µí•˜ëŠ” ì±—ë´‡",
    version="1.0.0"
)

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œì™€ í†µì‹ ì„ ìœ„í•´)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:5174", "http://localhost:5175"],  # Vite ê°œë°œ ì„œë²„ í¬íŠ¸ë“¤
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìš”ì²­ ë°ì´í„° ëª¨ë¸
class ChatRequest(BaseModel):
    message: str

# ì‘ë‹µ ë°ì´í„° ëª¨ë¸
class ChatResponse(BaseModel):
    response: str
    status: str = "success"

# ëŒ€í™” ê¸°ë¡ ëª¨ë¸
class ConversationMessage(BaseModel):
    role: str  # "user" ë˜ëŠ” "assistant"
    content: str

# ëŒ€í™” ê¸°ë¡ ì €ì¥ (ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì €ì¥)
conversation_history: List[ConversationMessage] = []

# OpenAI GPT í˜¸ì¶œ í•¨ìˆ˜
async def get_gpt_response(user_message: str) -> str:
    """OpenAI GPTë¥¼ ì‚¬ìš©í•˜ì—¬ í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
    try:
        # ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        conversation_history.append(ConversationMessage(role="user", content=user_message))
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•œ ë©”ì‹œì§€ êµ¬ì„±
        messages = [
            {"role": "system", "content": PERSONA}
        ]
        
        # ìµœê·¼ 10ê°œ ëŒ€í™”ë§Œ í¬í•¨ (í† í° ì œí•œ ê³ ë ¤)
        recent_history = conversation_history[-10:] if len(conversation_history) > 10 else conversation_history
        
        for msg in recent_history:
            messages.append({"role": msg.role, "content": msg.content})
        
        # OpenAI API í˜¸ì¶œ (GPT-4 mini ì‚¬ìš©)
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # GPT-4 mini
            messages=messages,
            max_tokens=500,
            temperature=0.7,
            top_p=0.9
        )
        
        assistant_response = response.choices[0].message.content.strip()
        
        # ëŒ€í™” ê¸°ë¡ì— ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì¶”ê°€
        conversation_history.append(ConversationMessage(role="assistant", content=assistant_response))
        
        return assistant_response
        
    except Exception as e:
        print(f"OpenAI API ì˜¤ë¥˜: {str(e)}")
        return f"ì–´? ë­”ê°€ ë¬¸ì œê°€ ìƒê²¼ë„¤ ğŸ˜… ë‹¤ì‹œ ì‹œë„í•´ë³¼ë˜? (ì˜¤ë¥˜: {str(e)})"

@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {"message": "Personality Chatbot API is running!", "status": "healthy"}

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ì„œ ê°œì¸í™”ëœ ë‹µë³€ì„ ë°˜í™˜í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    
    Args:
        request: ì‚¬ìš©ìì˜ ë©”ì‹œì§€ê°€ í¬í•¨ëœ ìš”ì²­ ë°ì´í„°
        
    Returns:
        ChatResponse: ì±—ë´‡ì˜ ë‹µë³€ê³¼ ìƒíƒœ ì •ë³´
    """
    try:
        user_message = request.message.strip()
        
        if not user_message:
            return ChatResponse(
                response="ì•ˆë…•! ë­”ê°€ ê¶ê¸ˆí•œ ê²Œ ìˆì–´? ğŸ˜Š",
                status="success"
            )
        
        # GPTë¥¼ ì‚¬ìš©í•œ í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        response_message = await get_gpt_response(user_message)
        
        return ChatResponse(
            response=response_message,
            status="success"
        )
        
    except Exception as e:
        return ChatResponse(
            response=f"ì–´? ë­”ê°€ ë¬¸ì œê°€ ìƒê²¼ë„¤ ğŸ˜… ë‹¤ì‹œ ì‹œë„í•´ë³¼ë˜?",
            status="error"
        )

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "message": "API is running normally"}

@app.post("/reset")
async def reset_conversation():
    """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ì—”ë“œí¬ì¸íŠ¸"""
    global conversation_history
    conversation_history.clear()
    return {"message": "ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!", "status": "success"}

@app.get("/history")
async def get_conversation_history():
    """í˜„ì¬ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "history": [{"role": msg.role, "content": msg.content} for msg in conversation_history],
        "count": len(conversation_history)
    }

if __name__ == "__main__":
    # ê°œë°œ ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # ì½”ë“œ ë³€ê²½ ì‹œ ìë™ ì¬ì‹œì‘
        log_level="info"
    )
